{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53bc677d-0083-4b83-a076-ee63bb1912a3",
   "metadata": {},
   "source": [
    "# Data Collection From PubMed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdc8e30-d418-4b17-b8fc-9f8f9bd04075",
   "metadata": {},
   "source": [
    "### Abstract Collection\n",
    "For this project, abstracts from a variety of scientific research papers were collected from PubMed to simulate a real-world scenario.\n",
    "\n",
    "The papers were selected based on specific topics relevant to common healthcare concerns, including:\n",
    "\n",
    "- Diabetes Management\n",
    "- Cardiovascular Risk\n",
    "- Oncology Treatment Updates\n",
    "- Thyroid Disorders\n",
    "- Respiratory Care\n",
    "- Vaccination Awareness\n",
    "  \n",
    "These topics were chosen randomly while considering their prevalence and relevance in current healthcare research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a66a034c-00b8-4c6c-b551-a66e4ff822df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "\n",
    "from Bio import Entrez\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4496eca7-27ef-4b54-955e-a8fd6504f966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching: Diabetes Management\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhand\\AppData\\Local\\Temp\\ipykernel_20832\\3056541766.py:16: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  soup = BeautifulSoup(handle.read(), \"lxml\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → 100 abstracts\n",
      "Fetching: Cardiovascular Risk\n",
      "  → 100 abstracts\n",
      "Fetching: Oncology Treatment Update\n",
      "  → 11 abstracts\n",
      "Fetching: Thyroid Disorders\n",
      "  → 99 abstracts\n",
      "Fetching: Respiratory Care\n",
      "  → 99 abstracts\n",
      "Fetching: Vaccination Awareness\n",
      "  → 100 abstracts\n",
      "Saved results to CSV\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "\n",
    "Entrez.email = \"bhandarirhea0697@gmail.com\"\n",
    "\n",
    "# Define search terms\n",
    "TOPICS = [\"Diabetes Management\", \"Cardiovascular Risk\", \"Oncology Treatment Update\", \"Thyroid Disorders\", \"Respiratory Care\", \"Vaccination Awareness\"]\n",
    "START_YEAR = \"2020\"\n",
    "END_YEAR = \"2025\"\n",
    "MAX_PER_TOPIC = 100\n",
    "\n",
    "\n",
    "# fetching scientific research articles topics from year 2020 to 2025\n",
    "def fetch_for_topic(term):\n",
    "    query = f'{term}[Title/Abstract] AND (\"{START_YEAR}\"[PDAT] : \"{END_YEAR}\"[PDAT])'\n",
    "    handle = Entrez.esearch(db=\"pubmed\", term=query, retmax=MAX_PER_TOPIC)\n",
    "    record = Entrez.read(handle)\n",
    "    pmids = record.get(\"IdList\", [])\n",
    "    if not pmids:\n",
    "        return []\n",
    "\n",
    "    handle = Entrez.efetch(db=\"pubmed\", id=\",\".join(pmids), rettype=\"abstract\", retmode=\"xml\")\n",
    "    soup = BeautifulSoup(handle.read(), \"lxml\")\n",
    "    results = []\n",
    "    for art in soup.find_all(\"pubmedarticle\"):\n",
    "        pmid = art.find(\"pmid\").text if art.find(\"pmid\") else \"\"\n",
    "        title = art.find(\"articletitle\").text if art.find(\"articletitle\") else \"\"\n",
    "        abstract = art.find(\"abstracttext\").text if art.find(\"abstracttext\") else \"\"\n",
    "        results.append({\"PMID\": pmid, \"Title\": title, \"Abstract\": abstract})\n",
    "    return results\n",
    "\n",
    "# Based on topics all the data were as dataframe and exported as csv\n",
    "def main():\n",
    "    all_data = []\n",
    "    for topic in TOPICS:\n",
    "        print(f\"Fetching: {topic}\")\n",
    "        data = fetch_for_topic(topic)\n",
    "        print(f\"  → {len(data)} abstracts\")\n",
    "        for d in data:\n",
    "            d[\"Topic\"] = topic\n",
    "        all_data.extend(data)\n",
    "        sleep(0.4)\n",
    "\n",
    "    df = pd.DataFrame(all_data)\n",
    "    df.to_csv(\"pubmed_abstracts_2020_2025.csv\", index=False)\n",
    "    print(\"Saved results to CSV\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
